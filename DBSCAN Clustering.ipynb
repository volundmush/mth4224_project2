{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e25d761-267d-4542-9d9b-b91668b3a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from cuml import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS, TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395f9e5d-fb9f-4edd-a347-67b4519276c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data sources\n",
    "raw_data = pd.read_csv(\"data/email_phishing_data.csv\")\n",
    "no_label_data = raw_data.drop('label', axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(no_label_data), columns=no_label_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91761a37-f4c7-40db-a022-e708360ec593",
   "metadata": {},
   "source": [
    "We will then use DBSCAN to see what clusters it makes. Using DBSCAN is expensive, so we reduce the number of columns using PCA. Values for DBSCAN params `min_samples` and `eps` were chosen by just messing around with DBSCAN on 30% of the data and general advice:\n",
    "- An `eps` value higher than 0.14 means all of the data gets grouped into one cluster. So I just used that. I then halved it in an attempt to get more clusters (it didn't have a drastic change).\n",
    "- `min_samples` was chosen from general advice found online to start with a min_samples that is $2 * d$, where $d$ is the number of features. For a 4D PCA decomposition, min_samples started at 8. There wasn't enough time to really test different values.\n",
    "\n",
    "The `cuml` library's implememntation of DBSCAN is used because otherwise it is too slow for our large dataset. `cuml` is a NVIDIA library making use of Cuda for GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa2c2fa-63b2-47e9-9f5c-529e2c4327f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# above used to suppress annoying CUDA warnings about integer sizing\n",
    "\n",
    "store_at = 'data_with_dbscan_cluster_df.pkl'\n",
    "if os.path.exists(store_at):\n",
    "    data_after_dbscan = pd.read_pickle(store_at)\n",
    "else:\n",
    "    pca = PCA(n_components=4, random_state=0)\n",
    "    # Commented out is for sklearn DBSCAN which was too slow, we use cuml library for GPU acceleration.\n",
    "    # dbscan = DBSCAN(n_jobs=4) # limit for available RAM when using sklearn DBSCAN\n",
    "    dbscan = DBSCAN(min_samples=8, eps=0.14, random_state=0)\n",
    "    data_after_dbscan = data.copy()\n",
    "    data_after_dbscan['cluster'] = dbscan.fit_predict(pca.fit_transform(data_after_dbscan))\n",
    "    data_after_dbscan['label'] = raw_data['label']\n",
    "    # storing data (it is expensive to run dbscan)\n",
    "    data_after_dbscan.to_pickle(store_at);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832a3f9c-de21-4ede-a333-9b6e201370e1",
   "metadata": {},
   "source": [
    "# Investigating Phishing Email / Total Ratio per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93ec75b-f78d-4022-bbda-6a057231e757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original percentage of phishing emails is 1.32%\n",
      "For cluster 0, percentage is 1.25%: 5276 out of 421818 points.\n",
      "For cluster 1, percentage is 1.41%: 1173 out of 83228 points.\n",
      "For cluster 2, percentage is 2.52%: 386 out of 15342 points.\n",
      "For cluster 3, percentage is 2.57%: 82 out of 3194 points.\n",
      "For cluster 4, percentage is 2.84%: 29 out of 1022 points.\n",
      "For cluster 5, percentage is 1.82%: 3 out of 165 points.\n",
      "For cluster 6, percentage is 0.00%: 0 out of 48 points.\n",
      "For cluster 7, percentage is 0.00%: 0 out of 11 points.\n"
     ]
    }
   ],
   "source": [
    "dataset_ratio = len(raw_data[raw_data['label'] == 1]) / len(raw_data)\n",
    "print(f'Original percentage of phishing emails is {dataset_ratio:.2%}')\n",
    "for c in data_after_dbscan['cluster'].unique():\n",
    "    if (c == -1): continue # handles the noise values from DBSCAN\n",
    "    cluster_data = data_after_dbscan[data_after_dbscan['cluster'] == c]\n",
    "    num_phishing = len(cluster_data[cluster_data['label'] == 1])\n",
    "    cluster_ratio = num_phishing / len(cluster_data)\n",
    "    print(f'For cluster {c}, percentage is {cluster_ratio:.2%}: {num_phishing} out of {len(cluster_data)} points.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
